{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDectionDisco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3W_ZoL96CcM",
        "outputId": "82e4b149-341c-44c8-ff32-02c7c71da243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone YOLOv5 and install requirements\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "import glob\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
        "\n",
        "import sys\n",
        "print(\"Python version\")\n",
        "print (sys.version)\n",
        "print(\"Version info.\")\n",
        "print (sys.version_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10T5G0xi6fog",
        "outputId": "bd4c7317-7885-4579-9eb7-28b53f18da2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n",
            "Setup complete. Using torch 1.11.0+cu102 (Tesla P100-PCIE-16GB)\n",
            "Python version\n",
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "Version info.\n",
            "sys.version_info(major=3, minor=7, micro=13, releaselevel='final', serial=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/AIImage\"\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "imgs = []\n",
        "\n",
        "for img in glob.glob(path + '/*.png'):\n",
        "  imgs.append(img)\n",
        "  #display(Image(filename = img))\n",
        "result = model(imgs)\n",
        "result.print()\n",
        "result.save()\n",
        "\n",
        "print(type(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAA7BzBSRj1w",
        "outputId": "fc76da22-4071-4897-a7b9-39f4c42a66de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2022-7-18 Python-3.7.13 torch-1.11.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
            "Adding AutoShape... \n",
            "Saved 7 images to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/7: 512x512 4 persons, 1 handbag, 2 baseball gloves\n",
            "image 2/7: 1024x1024 1 person, 1 bird, 2 sports balls\n",
            "image 3/7: 512x512 2 sports balls\n",
            "image 4/7: 512x512 1 person, 3 sports balls, 1 orange\n",
            "image 5/7: 512x512 5 cats, 1 bottle, 1 bowl\n",
            "image 6/7: 512x512 5 cats, 4 bowls\n",
            "image 7/7: 512x512 2 persons, 1 mouse, 1 vase\n",
            "Speed: 397.5ms pre-process, 30.5ms inference, 1.9ms NMS per image at shape (7, 3, 640, 640)\n",
            "<class 'models.common.Detections'>\n"
          ]
        }
      ]
    }
  ]
}