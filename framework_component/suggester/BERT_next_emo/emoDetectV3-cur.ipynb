{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "# model info, change as needed\n",
    "batch_size = 16\n",
    "num_epochs = 16\n",
    "\n",
    "# model_checkpoint = \"bert-base-uncased\"\n",
    "model_checkpoint = \"roberta-base\"\n",
    "# model_checkpoint= 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "metric_name = \"f1\"\n",
    "# fileTag = \"original-plutchik-v1\"\n",
    "fileTag = 'clean-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert dataset to suitable format\n",
    "IMPORTANT: please never run this section again if you have your dataset ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "9a1aa9f2cc29473f9f8e5459d2641e76",
      "308fa6a7348140ec981a8d6c7d31f346",
      "8bc92587e35443488445e7521fbd0a13",
      "091f8220f33241f288faa0612853585f",
      "1045bb16e3694410898a73cf1b848917",
      "cb95e545fbdd4e99903bf634df694c9f",
      "5080d322a8034924b652b379c04667ed",
      "8b1899a0c4b144d7a5e6599f8afb8b65",
      "6111a73e684a47769bda7183a836ee91",
      "cd3570ddf67541d7818d97e236c54e54",
      "bbba60f793c14100934a268063f63d26"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "1b5783cd-0e4e-4c92-c67c-57b9288f2381"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "trainDatasetOriginal = pd.read_csv(f'../../../data_process/dataset/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'../../../data_process/dataset/dev/emotion/allcharlinepairs-{fileTag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>emotionworkerid</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>affected</th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['joy', 'excited', 'content', 'hungry', 'antic...</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>['excited', 'confident']</td>\n",
       "      <td>{'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>3</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I let the curry sit before tasting.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['anxious', 'confident', 'positive']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>4</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>When it was time to taste, I was disgusted.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['upset', 'sick']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>5</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann1</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I accidentally used a whole garlic instead of ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>['disgusted', 'cretinous']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>11605</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>1</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['intrigued', 'happy', 'contemplative']</td>\n",
       "      <td>{'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>11606</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>2</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>He picked up a large beautiful shell.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['awestruck', 'moved', 'joy']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>11607</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>3</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>He put it in his pocket to save for later.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['satisfied', 'excited', 'curiosity']</td>\n",
       "      <td>{'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>11608</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>4</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>Suddenly he felt a sharp pinch.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['pained', 'sore', 'surprised']</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>11609</td>\n",
       "      <td>2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e</td>\n",
       "      <td>5</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Marcus was collecting shells on the beach.|He ...</td>\n",
       "      <td>A crab was inside the shell pinching his leg.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['shocked', 'surprised']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                               storyid  linenum        char  \\\n",
       "0               0  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "1               1  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "2               2  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        3  I (myself)   \n",
       "3               3  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        4  I (myself)   \n",
       "4               4  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        5  I (myself)   \n",
       "...           ...                                   ...      ...         ...   \n",
       "11605       11605  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        1      Marcus   \n",
       "11606       11606  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        2      Marcus   \n",
       "11607       11607  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        3      Marcus   \n",
       "11608       11608  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        4      Marcus   \n",
       "11609       11609  2aa1aca3-9264-4e27-9ebb-fa5de8e7e84e        5      Marcus   \n",
       "\n",
       "      emotionworkerid                                            context  \\\n",
       "0                ann0                                                NaN   \n",
       "1                ann1  I began making fish curry for my boyfriend and I.   \n",
       "2                ann0  I began making fish curry for my boyfriend and...   \n",
       "3                ann1  I began making fish curry for my boyfriend and...   \n",
       "4                ann1  I began making fish curry for my boyfriend and...   \n",
       "...               ...                                                ...   \n",
       "11605            ann0                                                NaN   \n",
       "11606            ann0         Marcus was collecting shells on the beach.   \n",
       "11607            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "11608            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "11609            ann0  Marcus was collecting shells on the beach.|He ...   \n",
       "\n",
       "                                                sentence affected  \\\n",
       "0      I began making fish curry for my boyfriend and I.      yes   \n",
       "1      I decided not to read a recipe since I've made...      yes   \n",
       "2                    I let the curry sit before tasting.      yes   \n",
       "3            When it was time to taste, I was disgusted.      yes   \n",
       "4      I accidentally used a whole garlic instead of ...      yes   \n",
       "...                                                  ...      ...   \n",
       "11605         Marcus was collecting shells on the beach.      yes   \n",
       "11606              He picked up a large beautiful shell.      yes   \n",
       "11607         He put it in his pocket to save for later.      yes   \n",
       "11608                    Suddenly he felt a sharp pinch.      yes   \n",
       "11609      A crab was inside the shell pinching his leg.      yes   \n",
       "\n",
       "                                                 emotion  \\\n",
       "0      ['joy', 'excited', 'content', 'hungry', 'antic...   \n",
       "1                               ['excited', 'confident']   \n",
       "2                   ['anxious', 'confident', 'positive']   \n",
       "3                                      ['upset', 'sick']   \n",
       "4                             ['disgusted', 'cretinous']   \n",
       "...                                                  ...   \n",
       "11605            ['intrigued', 'happy', 'contemplative']   \n",
       "11606                      ['awestruck', 'moved', 'joy']   \n",
       "11607              ['satisfied', 'excited', 'curiosity']   \n",
       "11608                    ['pained', 'sore', 'surprised']   \n",
       "11609                           ['shocked', 'surprised']   \n",
       "\n",
       "                                                plutchik  \n",
       "0      {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "1      {'joy': 2, 'trust': 3, 'fear': 0, 'surprise': ...  \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...  \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "...                                                  ...  \n",
       "11605  {'joy': 3, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11606  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11607  {'joy': 2, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "11608  {'joy': 1, 'trust': 0, 'fear': 2, 'surprise': ...  \n",
       "11609  {'joy': 0, 'trust': 0, 'fear': 3, 'surprise': ...  \n",
       "\n",
       "[11610 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "inputMode = \"prevSent\"\n",
    "trainDatasetProcessed = DataFrame({'sentence' : trainDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'surprise': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['surprise'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'anticipation': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['anticipation'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])]})\n",
    "testDatasetProcessed = DataFrame({'sentence' : testDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'surprise': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['surprise'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'anticipation': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['anticipation'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "inputMode = \"prevSent-rem2Cl\"\n",
    "trainDatasetProcessed = DataFrame({'sentence' : trainDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])]})\n",
    "testDatasetProcessed = DataFrame({'sentence' : testDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "inputMode = \"prevSent-onlyTrust\"\n",
    "trainDatasetProcessed = DataFrame({'sentence' : trainDatasetOriginal['sentence'], \n",
    "                                   'trust' : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])]})\n",
    "testDatasetProcessed = DataFrame({'sentence' : testDatasetOriginal['sentence'], \n",
    "                                   'trust' : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "inputMode = \"prevSent-onlyJoy\"\n",
    "trainDatasetProcessed = DataFrame({'sentence' : trainDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])]})\n",
    "testDatasetProcessed = DataFrame({'sentence' : testDatasetOriginal['sentence'], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "inputMode = \"context+prevSent\"\n",
    "trainDatasetProcessed = DataFrame({'sentence' : [x.replace(\"|\", \" \") for x in trainDatasetOriginal['context'].fillna(\"\") + \" \" +trainDatasetOriginal['sentence']], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'surprise': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['surprise'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])],\n",
    "                                   'anticipation': [0 if (ast.literal_eval(trainDatasetOriginal['plutchik'][index])['anticipation'] == 0) else 1 for index in range(trainDatasetOriginal.shape[0])]})\n",
    "testDatasetProcessed = DataFrame({'sentence' : [x.replace(\"|\", \" \") for x in testDatasetOriginal['context'].fillna(\"\") + \" \" +testDatasetOriginal['sentence']], \n",
    "                                   'joy'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['joy'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'trust' : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['trust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])], \n",
    "                                   'fear'  : [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['fear'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'surprise': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['surprise'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'sadness': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['sadness'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'disgust': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['disgust'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'anger': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['anger'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])],\n",
    "                                   'anticipation': [0 if (ast.literal_eval(testDatasetOriginal['plutchik'][index])['anticipation'] == 0) else 1 for index in range(testDatasetOriginal.shape[0])]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I began making fish curry for my boyfriend an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  joy  trust  fear  \\\n",
       "0       I began making fish curry for my boyfriend an...    1      1     0   \n",
       "1      I began making fish curry for my boyfriend and...    1      1     0   \n",
       "2      I began making fish curry for my boyfriend and...    1      1     0   \n",
       "3      I began making fish curry for my boyfriend and...    0      0     1   \n",
       "4      I began making fish curry for my boyfriend and...    0      0     0   \n",
       "...                                                  ...  ...    ...   ...   \n",
       "11605         Marcus was collecting shells on the beach.    1      1     0   \n",
       "11606  Marcus was collecting shells on the beach. He ...    1      1     0   \n",
       "11607  Marcus was collecting shells on the beach. He ...    1      1     0   \n",
       "11608  Marcus was collecting shells on the beach. He ...    1      0     1   \n",
       "11609  Marcus was collecting shells on the beach. He ...    0      0     1   \n",
       "\n",
       "       surprise  sadness  disgust  anger  anticipation  \n",
       "0             1        0        0      0             1  \n",
       "1             0        0        0      0             1  \n",
       "2             0        0        0      0             1  \n",
       "3             1        0        1      1             0  \n",
       "4             1        1        1      1             0  \n",
       "...         ...      ...      ...    ...           ...  \n",
       "11605         1        0        0      0             1  \n",
       "11606         1        0        0      0             1  \n",
       "11607         1        0        0      0             1  \n",
       "11608         1        1        1      1             1  \n",
       "11609         1        0        0      0             1  \n",
       "\n",
       "[11610 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainDatasetProcessed\n",
    "# trainDatasetProcessed = pd.concat([trainDatasetProcessed, testDatasetProcessed]).sample(frac=1).reset_index(drop=True) # shuffle and combine everything, ratio issue fix here!\n",
    "trainDatasetProcessed.to_csv(f'./dataset/curEmo/emoDetect-{fileTag}-{inputMode}-train.csv')\n",
    "trainDatasetProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I began making fish curry for my boyfriend an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>Marcus was collecting shells on the beach.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>Marcus was collecting shells on the beach. He ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  joy  trust  fear  \\\n",
       "0       I began making fish curry for my boyfriend an...    1      1     0   \n",
       "1      I began making fish curry for my boyfriend and...    1      1     0   \n",
       "2      I began making fish curry for my boyfriend and...    1      1     0   \n",
       "3      I began making fish curry for my boyfriend and...    0      0     1   \n",
       "4      I began making fish curry for my boyfriend and...    0      0     0   \n",
       "...                                                  ...  ...    ...   ...   \n",
       "11605         Marcus was collecting shells on the beach.    1      1     0   \n",
       "11606  Marcus was collecting shells on the beach. He ...    1      1     0   \n",
       "11607  Marcus was collecting shells on the beach. He ...    1      1     0   \n",
       "11608  Marcus was collecting shells on the beach. He ...    1      0     1   \n",
       "11609  Marcus was collecting shells on the beach. He ...    0      0     1   \n",
       "\n",
       "       surprise  sadness  disgust  anger  anticipation  \n",
       "0             1        0        0      0             1  \n",
       "1             0        0        0      0             1  \n",
       "2             0        0        0      0             1  \n",
       "3             1        0        1      1             0  \n",
       "4             1        1        1      1             0  \n",
       "...         ...      ...      ...    ...           ...  \n",
       "11605         1        0        0      0             1  \n",
       "11606         1        0        0      0             1  \n",
       "11607         1        0        0      0             1  \n",
       "11608         1        1        1      1             1  \n",
       "11609         1        0        0      0             1  \n",
       "\n",
       "[11610 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDatasetProcessed.to_csv(f'./dataset/curEmo/emoDetect-{fileTag}-{inputMode}-test.csv')\n",
    "testDatasetProcessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCL02vQgxYTO"
   },
   "source": [
    "# Start convert and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRd1kXQZjYIY",
    "outputId": "8021590c-5607-4a9c-a474-bc57da503c93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c26f10be60c63a64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-c26f10be60c63a64\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f566c24c31415396ddb772e098728b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43750201e2c34a9893bfa6bb949f94e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\JAM_0\\.cache\\huggingface\\datasets\\csv\\default-c26f10be60c63a64\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a338f0df338745dc90e1c2d43f8f5285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'sentence', 'joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'sentence', 'joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation'],\n",
       "        num_rows: 11610\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "dataset = load_dataset('csv', data_files={'train': f'./dataset/curEmo/emoDetect-{fileTag}-{inputMode}-train.csv', \n",
    "                                           'test': f'./dataset/curEmo/emoDetect-{fileTag}-{inputMode}-test.csv'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgS0wMWExcqP"
   },
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unjuTtKUjZI3",
    "outputId": "6f1e5051-8272-40f9-ced8-ba17a105e904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 1,\n",
       " 'sentence': \"I began making fish curry for my boyfriend and I. I decided not to read a recipe since I've made so many in my life.\",\n",
       " 'joy': 1,\n",
       " 'trust': 1,\n",
       " 'fear': 0,\n",
       " 'surprise': 0,\n",
       " 'sadness': 0,\n",
       " 'disgust': 0,\n",
       " 'anger': 0,\n",
       " 'anticipation': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][1]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DV0Rtetxgd4"
   },
   "source": [
    "The dataset consists of tweets, labeled with one or more emotions. \n",
    "\n",
    "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5vZhQpvkE8s",
    "outputId": "5d513b30-f209-492f-c6ab-245d64a67d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'trust',\n",
       " 'fear',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'anticipation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'].features.keys() if label not in ['Unnamed: 0', 'sentence']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ3Teyjmank2"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5883ef2b974712bf31626877eb5dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605bfbfb1bf24d219dfb5ee8df0bf73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5350ae957e41f0a4c585f2821ba175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d253cb9d3a74e3abf83d0ef90171505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"sentence\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_data at 0x000002964CF794C0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc842ee6ad94cd4b3156a476f0b1d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a8a7c35c6c4c9b8dc635aca972c1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enAb0W9o25W",
    "outputId": "55bc5ba6-d169-49c6-f562-bb7ea4143866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][2]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "D0McCtJ8HRJY",
    "outputId": "82fb0336-51a3-40ad-ebc0-65eeb7cf4b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>I began making fish curry for my boyfriend and I. I decided not to read a recipe since I've made so many in my life. I let the curry sit before tasting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdIvj6WjHeZQ",
    "outputId": "418c14d2-cca3-44e9-d0a2-6ad4ca7a007c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Dx95t2o6N9",
    "outputId": "3ce6c923-0b45-4743-bc4b-7771d088b03e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'trust', 'anticipation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgpKXDfvKBxn"
   },
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lk6Cq9duKBkA"
   },
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "22994300-8c93-421e-faa4-678d6cc14aab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9a9dfb18844eda9e39d9e09d833650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id, \n",
    "                                                           ignore_mismatched_sizes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJGEXShp7te"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dR2GmpvDqbuZ"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"roberta-finetuned-emoDetect\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    # learning_rate=6e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_v2fPFFJ3-v"
   },
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "797b2WHJqUgZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "validationInfo = []\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    validationInfo.append([y_true, probs])\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxNo4_TsvzDm"
   },
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IlOgGiojuWwG",
    "outputId": "cd0b2c99-b520-468d-8ffc-c36211b7820a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y41Kre_jvD7x",
    "outputId": "b6ca888b-6371-40fb-ab83-3dc24d28320a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,    38,   880,   442,  3539, 30040,    13,   127,  6578,     8,\n",
       "           38,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxWcnZ8ku12V",
    "outputId": "26522911-c3cd-466a-ae2d-d81d23003c23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6741, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.0449, -0.1280, -0.1787,  0.1029, -0.0488, -0.0984, -0.0420,  0.0259]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "chq_3nUz73ib"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KXmFds8js6P8",
    "outputId": "66ebb2ab-f93f-48aa-a4dc-36f55f2f8559",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\miniconda3\\envs\\pytorchEnvWithDataSci\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11610\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11616\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5333' max='11616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5333/11616 14:16 < 16:49, 6.22 it/s, Epoch 7.34/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>0.591995</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>0.641955</td>\n",
       "      <td>0.059001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.491829</td>\n",
       "      <td>0.728772</td>\n",
       "      <td>0.758261</td>\n",
       "      <td>0.166064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.474994</td>\n",
       "      <td>0.735022</td>\n",
       "      <td>0.766870</td>\n",
       "      <td>0.177089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.462259</td>\n",
       "      <td>0.748867</td>\n",
       "      <td>0.778071</td>\n",
       "      <td>0.197588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.453417</td>\n",
       "      <td>0.755303</td>\n",
       "      <td>0.784544</td>\n",
       "      <td>0.208355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.444052</td>\n",
       "      <td>0.761223</td>\n",
       "      <td>0.790016</td>\n",
       "      <td>0.217743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.436996</td>\n",
       "      <td>0.763891</td>\n",
       "      <td>0.792985</td>\n",
       "      <td>0.218691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-726\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-726\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-726\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-726\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-726\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-1452\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-1452\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-1452\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-1452\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-1452\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-2178\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-2178\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-2178\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-2178\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-2178\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-2904\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-2904\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-2904\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-2904\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-2904\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-3630\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-3630\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-3630\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-3630\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-3630\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-4356\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-4356\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-4356\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-4356\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-4356\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11610\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to roberta-finetuned-emoDetect\\checkpoint-5082\n",
      "Configuration saved in roberta-finetuned-emoDetect\\checkpoint-5082\\config.json\n",
      "Model weights saved in roberta-finetuned-emoDetect\\checkpoint-5082\\pytorch_model.bin\n",
      "tokenizer config file saved in roberta-finetuned-emoDetect\\checkpoint-5082\\tokenizer_config.json\n",
      "Special tokens file saved in roberta-finetuned-emoDetect\\checkpoint-5082\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "import pandas as pd\n",
    "\n",
    "y_test = validationInfo[pd.DataFrame(trainer.state.log_history)['eval_accuracy'].dropna().reset_index(drop=True).idxmax()][0]\n",
    "y_score = validationInfo[pd.DataFrame(trainer.state.log_history)['eval_accuracy'].dropna().reset_index(drop=True).idxmax()][1]\n",
    "plt.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "currentAcc = round(pd.DataFrame(trainer.state.log_history)['eval_accuracy'].dropna().reset_index(drop=True).max() * 100, 2)\n",
    "n_classes = 8\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for index, label in enumerate(id2label.values()):\n",
    "    fpr[label], tpr[label], _ = roc_curve(y_test[:, index], y_score[:, index])\n",
    "    roc_auc[label] = auc(fpr[label], tpr[label])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[label] for index, label in enumerate(id2label.values())]))\n",
    "lw = 2\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for index, label in enumerate(id2label.values()):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[label], tpr[label])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"red\", \"blue\", \"green\", \"orange\", \"green\", \"purple\", \"pink\", \"grey\"])\n",
    "for i, color in zip([label for index, label in enumerate(id2label.values())], colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(f\"ROC curve\", loc = 'right')\n",
    "# plt.title(f\"data: {fileTag} \\\n",
    "#           \\ninput: previous sentence + previous context\\\n",
    "#           \\nmodel: {model_checkpoint}\\\n",
    "#           \\ntask: current sentence --> current emotion\\\n",
    "#           \\nmax acc: {currentAcc}%\", loc='left')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataLog = pd.DataFrame(trainer.state.log_history)\n",
    "dataLog.to_csv(f'./trainingMetric/curEmo/TI-{model_checkpoint}-{fileTag}-{inputMode}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nmvJp0pLq-3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fxjfr8PLD42"
   },
   "outputs": [],
   "source": [
    "text = \"I love the hell\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {k: v.to(model.device) for k,v in encoding.items()}\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**encoding)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THm5-XgNHPm"
   },
   "source": [
    "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOBosj4UL2tU",
    "outputId": "be370f49-3840-4c76-b193-76083e49701e"
   },
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC4XdDaHNVcd"
   },
   "source": [
    "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
    "\n",
    "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEkAQleMMT0k",
    "outputId": "fddb51cb-bf01-420a-fd5b-4a7c2e775446"
   },
   "outputs": [],
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorchEnvWithDataSci",
   "language": "python",
   "name": "pytorchenvwithdatasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
